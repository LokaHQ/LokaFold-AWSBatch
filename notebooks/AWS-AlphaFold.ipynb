{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc5-mbsX9PZC"
      },
      "source": [
        "# AWS-AlphaFold Notebook\n",
        "\n",
        "This notebook allows you to easily predict the structure of a protein using a modified version of [AlphaFold v2.1.0](https://doi.org/10.1038/s41586-021-03819-2). \n",
        "\n",
        "**Differences to AlphaFold v2.1.0**\n",
        "\n",
        "In comparison to AlphaFold v2.1.0, this notebook uses AWS Batch to submit protein analysis jobs to a scalable compute cluster. The accuracy should be the same as if you ran it locally. However, by using HPC services like AWS Batch and Amazon FSx for Lustre, we can support parallel job execution and optimize the resources for each run.\n",
        "\n",
        "**Citing this work**\n",
        "\n",
        "Any publication that discloses findings arising from using this notebook should [cite](https://github.com/deepmind/alphafold/#citing-this-work) the [AlphaFold paper](https://doi.org/10.1038/s41586-021-03819-2).\n",
        "\n",
        "**Licenses**\n",
        "\n",
        "This notebook uses the [AlphaFold model parameters](https://github.com/deepmind/alphafold/#model-parameters-license) and its outputs are thus for non-commercial use only, under the Creative Commons Attribution-NonCommercial 4.0 International ([CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/legalcode)) license. The notebook itself is provided under the [MIT 0 license](https://github.com/aws/mit-0). \n",
        "\n",
        "**More information**\n",
        "\n",
        "You can find more information about how AlphaFold works in the following papers:\n",
        "\n",
        "*   [AlphaFold methods paper](https://www.nature.com/articles/s41586-021-03819-2)\n",
        "*   [AlphaFold predictions of the human proteome paper](https://www.nature.com/articles/s41586-021-03828-1)\n",
        "*   [AlphaFold-Multimer paper](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v1)\n",
        "\n",
        "FAQ on how to interpret AlphaFold predictions are [here](https://alphafold.ebi.ac.uk/faq)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -r notebook-requirements.txt -q -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " ## Import helper functions at rfutils/rfutils.py\n",
        "from nbhelpers import nbhelpers\n",
        "\n",
        "# Import required Python packages\n",
        "from alphafold.notebooks import notebook_utils\n",
        "from alphafold.model import config\n",
        "import boto3\n",
        "from datetime import datetime\n",
        "import sagemaker\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "pd.set_option(\"max_colwidth\", None)\n",
        "\n",
        "# Get client informatiion\n",
        "boto_session = boto3.session.Session()\n",
        "sm_session = sagemaker.session.Session()\n",
        "region = boto_session.region_name\n",
        "s3_client = boto3.client(\"s3\", region_name=region)\n",
        "batch_client = boto3.client(\"batch\")\n",
        "default_bucket = sm_session.default_bucket()\n",
        "print(f\"Default S3 bucket name is {default_bucket}\")\n",
        "\n",
        "S3_BUCKET = default_bucket\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you have multiple AWS-Alphafold stacks deployed in your account, which one should we use?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nbhelpers.list_alphafold_stacks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Pick a stack to use for prediction\n",
        "my_stack = \"awsaf-220110\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4JpOs6oA-QS"
      },
      "source": [
        "## 1. Run a one-step prediction job (monomer)\n",
        "\n",
        "Please paste the sequence of your protein in the text box below, then run the remaining cells via _Runtime_ > _Run after_. You can also run the cells individually by pressing the _Play_ button on the left.\n",
        "\n",
        "Note that the search against databases and the actual prediction can take some time, from minutes to hours, depending on the length of the protein and what type of GPU you are allocated by Colab (see FAQ below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Provide sequences for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rowN0bVYLe9n"
      },
      "outputs": [],
      "source": [
        "## Enter the amino acid sequence to fold \n",
        "\n",
        "########### Required Inputs #################################\n",
        "id_1 = \"5ZNG_1\"\n",
        "sequence_1 = \"MDLSNMESVVESALTGQRTKIVVKVHMPCGKSRAKAMALAASVNGVDSVEITGEDKDRLVVVGRGIDPVRLVALLREKCGLAELLMVELVEKEKTQLAGGKKGAYKKHPTYNLSPFDYVEYPPSAPIMQDINPCSTM\"\n",
        "#################################################\n",
        "id_2 = \"\"\n",
        "sequence_2 = \"\"\n",
        "\n",
        "input_ids = (id_1, id_2)\n",
        "input_sequences = (sequence_1, sequence_2)\n",
        "\n",
        "\n",
        "# If folding a complex target and all the input sequences are\n",
        "# prokaryotic then set `is_prokaryotic` to `True`. Set to `False`\n",
        "# otherwise or if the origin is unknown.\n",
        "IS_PROKARYOTE = False  \n",
        "\n",
        "MIN_SINGLE_SEQUENCE_LENGTH = 16\n",
        "MAX_SINGLE_SEQUENCE_LENGTH = 2500\n",
        "MAX_MULTIMER_LENGTH = 2500\n",
        "MAX_TEMPLATE_DATE = \"2022-01-01\"\n",
        "DB_PRESET = \"reduced_dbs\"\n",
        "RUN_FEATURES_ONLY = False\n",
        "BENCHMARK = False\n",
        "USE_PRECOMPUTED_MSAS = False    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validate the input and determine which models to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sequences, model_type_to_use = notebook_utils.validate_input(\n",
        "    input_sequences=input_sequences,\n",
        "    min_length=MIN_SINGLE_SEQUENCE_LENGTH,\n",
        "    max_length=MAX_SINGLE_SEQUENCE_LENGTH,\n",
        "    max_multimer_length=MAX_MULTIMER_LENGTH)\n",
        "\n",
        "if model_type_to_use == notebook_utils.ModelType.MONOMER:\n",
        "    model_preset = \"monomer\"\n",
        "    model_names = config.MODEL_PRESETS['monomer'] + ('model_2_ptm',)\n",
        "elif model_type_to_use == notebook_utils.ModelType.MULTIMER:\n",
        "    model_preset = \"multimer\"\n",
        "    model_names = config.MODEL_PRESETS['multimer']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Upload input file to S3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_name = nbhelpers.create_job_name()\n",
        "object_key = nbhelpers.upload_fasta_to_s3(sequences, input_ids, S3_BUCKET, job_name, region=region)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Submit AWS Batch job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = nbhelpers.submit_batch_alphafold_job(\n",
        "    job_name=str(job_name),\n",
        "    fasta_paths = object_key,\n",
        "    output_dir = job_name,\n",
        "    db_preset = DB_PRESET,\n",
        "    model_preset = model_preset,\n",
        "    s3_bucket = S3_BUCKET,\n",
        "    cpu = 8,\n",
        "    memory = 16,\n",
        "    gpu = 1,\n",
        "    stack_name = my_stack\n",
        ")\n",
        "\n",
        "print(f\"Job ID {response['jobId']} submitted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check status of jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "status = nbhelpers.get_batch_job_info(response['jobId'])\n",
        "print(f\"Job {status['jobName']} is in {status['status']} status\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View job logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#nbhelpers.get_batch_logs(status[\"logStreamName\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View MSA information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# job_name=\"20220113T162425\"\n",
        "# nbhelpers.plot_msa(S3_BUCKET, job_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View predicted structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# nbhelpers.display_structure(S3_BUCKET, job_name, vmin=0.5, vmax=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4JpOs6oA-QS"
      },
      "source": [
        "## 2. Run a one-step prediction job (multimer)\n",
        "\n",
        "Please paste the sequence of your protein in the text box below, then run the remaining cells via _Runtime_ > _Run after_. You can also run the cells individually by pressing the _Play_ button on the left.\n",
        "\n",
        "Note that the search against databases and the actual prediction can take some time, from minutes to hours, depending on the length of the protein and what type of GPU you are allocated by Colab (see FAQ below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Provide sequences for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rowN0bVYLe9n"
      },
      "outputs": [],
      "source": [
        "## Enter the amino acid sequence to fold \n",
        "\n",
        "id_1 = \"5ZNG_1\"\n",
        "sequence_1 = \"MDLSNMESVVESALTGQRTKIVVKVHMPCGKSRAKAMALAASVNGVDSVEITGEDKDRLVVVGRGIDPVRLVALLREKCGLAELLMVELVEKEKTQLAGGKKGAYKKHPTYNLSPFDYVEYPPSAPIMQDINPCSTM\"\n",
        "\n",
        "id_2 = '5ZNG_2'\n",
        "sequence_2 = 'MAWKDCIIQRYKDGDVNNIYTANRNEEITIEEYKVFVNEACHPYPVILPDRSVLSGDFTSAYADDDESCYRHHHHHH'\n",
        "\n",
        "id_3 = ''\n",
        "sequence_3 = ''\n",
        "id_4 = ''\n",
        "sequence_4 = ''\n",
        "id_5 = ''\n",
        "sequence_5 = ''\n",
        "id_6 = ''\n",
        "sequence_6 = ''\n",
        "id_7 = ''\n",
        "sequence_7 = ''\n",
        "id_8 = ''\n",
        "sequence_8 = ''\n",
        "\n",
        "input_ids = (id_1, id_2, id_3, id_4,\n",
        "                   id_5, id_6, id_7, id_8)\n",
        "input_sequences = (sequence_1, sequence_2, sequence_3, sequence_4,\n",
        "                   sequence_5, sequence_6, sequence_7, sequence_8)\n",
        "\n",
        "\n",
        "# If folding a complex target and all the input sequences are\n",
        "# prokaryotic then set `is_prokaryotic` to `True`. Set to `False`\n",
        "# otherwise or if the origin is unknown.\n",
        "IS_PROKARYOTE = False  \n",
        "\n",
        "MIN_SINGLE_SEQUENCE_LENGTH = 16\n",
        "MAX_SINGLE_SEQUENCE_LENGTH = 2500\n",
        "MAX_MULTIMER_LENGTH = 2500\n",
        "MAX_TEMPLATE_DATE = \"2022-01-01\"\n",
        "DB_PRESET = \"reduced_dbs\"\n",
        "RUN_FEATURES_ONLY = False\n",
        "BENCHMARK = False\n",
        "USE_PRECOMPUTED_MSAS = False    \n",
        "\n",
        "sequences, model_type_to_use = notebook_utils.validate_input(\n",
        "    input_sequences=input_sequences,\n",
        "    min_length=MIN_SINGLE_SEQUENCE_LENGTH,\n",
        "    max_length=MAX_SINGLE_SEQUENCE_LENGTH,\n",
        "    max_multimer_length=MAX_MULTIMER_LENGTH)\n",
        "\n",
        "if model_type_to_use == notebook_utils.ModelType.MONOMER:\n",
        "    model_preset = \"monomer\"\n",
        "    model_names = config.MODEL_PRESETS['monomer'] + ('model_2_ptm',)\n",
        "elif model_type_to_use == notebook_utils.ModelType.MULTIMER:\n",
        "    model_preset = \"multimer\"\n",
        "    model_names = config.MODEL_PRESETS['multimer']\n",
        "\n",
        "# Upload input file to S3\n",
        "job_name = nbhelpers.create_job_name()\n",
        "object_key = nbhelpers.upload_fasta_to_s3(sequences, input_ids, S3_BUCKET, job_name, region=region)       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Submit batch job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Submit AWS Batch job\n",
        "response = nbhelpers.submit_batch_alphafold_job(\n",
        "    job_name=str(job_name),\n",
        "    fasta_paths = object_key,\n",
        "    output_dir = job_name,\n",
        "    db_preset = DB_PRESET,\n",
        "    model_preset = model_preset,\n",
        "    s3_bucket = S3_BUCKET,\n",
        "    cpu = 8,\n",
        "    memory = 16,\n",
        "    gpu = 1,\n",
        "    stack_name = my_stack\n",
        ")\n",
        "\n",
        "print(f\"Job ID {response['jobId']} submitted\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check status of jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "status = nbhelpers.get_batch_job_info(response['jobId'])\n",
        "print(f\"Job {status['jobName']} is in {status['status']} status\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View job logs and results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#nbhelpers.get_batch_logs(status[\"logStreamName\"])\n",
        "# job_name=\"20220113T162425\"\n",
        "# nbhelpers.plot_msa(S3_BUCKET, job_name)\n",
        "# nbhelpers.display_structure(S3_BUCKET, job_name, vmin=0.5, vmax=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Run a two-step prediction job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Enter the amino acid sequence to fold \n",
        "\n",
        "########### Required Inputs #################################\n",
        "id_1 = \"5ZNG_1\"\n",
        "sequence_1 = \"MDLSNMESVVESALTGQRTKIVVKVHMPCGKSRAKAMALAASVNGVDSVEITGEDKDRLVVVGRGIDPVRLVALLREKCGLAELLMVELVEKEKTQLAGGKKGAYKKHPTYNLSPFDYVEYPPSAPIMQDINPCSTM\"\n",
        "#################################################\n",
        "\n",
        "id_2 = \"\"\n",
        "sequence_2 = \"\"\n",
        "id_3 = ''\n",
        "sequence_3 = ''\n",
        "id_4 = ''\n",
        "sequence_4 = ''\n",
        "id_5 = ''\n",
        "sequence_5 = ''\n",
        "id_6 = ''\n",
        "sequence_6 = ''\n",
        "id_7 = ''\n",
        "sequence_7 = ''\n",
        "id_8 = ''\n",
        "sequence_8 = ''\n",
        "\n",
        "input_ids = (id_1, id_2, id_3, id_4,\n",
        "                   id_5, id_6, id_7, id_8)\n",
        "input_sequences = (sequence_1, sequence_2, sequence_3, sequence_4,\n",
        "                   sequence_5, sequence_6, sequence_7, sequence_8)\n",
        "\n",
        "\n",
        "# If folding a complex target and all the input sequences are\n",
        "# prokaryotic then set `is_prokaryotic` to `True`. Set to `False`\n",
        "# otherwise or if the origin is unknown.\n",
        "IS_PROKARYOTE = False  \n",
        "\n",
        "MIN_SINGLE_SEQUENCE_LENGTH = 16\n",
        "MAX_SINGLE_SEQUENCE_LENGTH = 2500\n",
        "MAX_MULTIMER_LENGTH = 2500\n",
        "MAX_TEMPLATE_DATE = \"2022-01-01\"\n",
        "DB_PRESET = \"reduced_dbs\"\n",
        "RUN_FEATURES_ONLY = False\n",
        "BENCHMARK = False\n",
        "USE_PRECOMPUTED_MSAS = False    \n",
        "\n",
        "sequences, model_type_to_use = notebook_utils.validate_input(\n",
        "    input_sequences=input_sequences,\n",
        "    min_length=MIN_SINGLE_SEQUENCE_LENGTH,\n",
        "    max_length=MAX_SINGLE_SEQUENCE_LENGTH,\n",
        "    max_multimer_length=MAX_MULTIMER_LENGTH)\n",
        "\n",
        "if model_type_to_use == notebook_utils.ModelType.MONOMER:\n",
        "    model_preset = \"monomer\"\n",
        "    model_names = config.MODEL_PRESETS['monomer'] + ('model_2_ptm',)\n",
        "elif model_type_to_use == notebook_utils.ModelType.MULTIMER:\n",
        "    model_preset = \"multimer\"\n",
        "    model_names = config.MODEL_PRESETS['multimer']\n",
        "\n",
        "# Upload input file to S3\n",
        "job_name = nbhelpers.create_job_name()\n",
        "object_key = nbhelpers.upload_fasta_to_s3(sequences, input_ids, S3_BUCKET, job_name, region=region)       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "step_1_response = nbhelpers.submit_batch_alphafold_job(\n",
        "    job_name=str(job_name),\n",
        "    fasta_paths = object_key,\n",
        "    output_dir = job_name,\n",
        "    db_preset = DB_PRESET,\n",
        "    model_preset = model_preset,\n",
        "    s3_bucket = S3_BUCKET,\n",
        "    cpu = 8,\n",
        "    memory = 32,\n",
        "    gpu = 0,\n",
        "    run_features_only = True,\n",
        "    stack_name = my_stack,\n",
        ")\n",
        "\n",
        "print(f\"Job ID {step_1_response['jobId']} submitted\")\n",
        "\n",
        "step_2_response = nbhelpers.submit_batch_alphafold_job(\n",
        "    job_name=str(job_name),\n",
        "    fasta_paths = object_key,\n",
        "    output_dir = job_name,\n",
        "    db_preset = DB_PRESET,\n",
        "    model_preset = model_preset,\n",
        "    s3_bucket = S3_BUCKET,\n",
        "    cpu = 8,\n",
        "    memory = 16,\n",
        "    gpu = 1,    \n",
        "    features_paths = os.path.join(job_name,\"features.pkl\"),\n",
        "    depends_on = step_1_response['jobId'],\n",
        "    stack_name = my_stack,\n",
        ")\n",
        "\n",
        "print(f\"Job ID {step_2_response['jobId']} submitted\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUQAn5LYC5n4"
      },
      "source": [
        "### Interpreting the prediction\n",
        "\n",
        "In general predicted LDDT (pLDDT) is best used for intra-domain confidence, whereas Predicted Aligned Error (PAE) is best used for determining between domain or between chain confidence.\n",
        "\n",
        "Please see the [AlphaFold methods paper](https://www.nature.com/articles/s41586-021-03819-2), the [AlphaFold predictions of the human proteome paper](https://www.nature.com/articles/s41586-021-03828-1), and the [AlphaFold-Multimer paper](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v1) as well as [our FAQ](https://alphafold.ebi.ac.uk/faq) on how to interpret AlphaFold predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeb2z8DIA4om"
      },
      "source": [
        "## FAQ & Troubleshooting\n",
        "\n",
        "\n",
        "*   How do I get a predicted protein structure for my protein?\n",
        "    *   Click on the _Connect_ button on the top right to get started.\n",
        "    *   Paste the amino acid sequence of your protein (without any headers) into the “Enter the amino acid sequence to fold”.\n",
        "    *   Run all cells in the Colab, either by running them individually (with the play button on the left side) or via _Runtime_ > _Run all._\n",
        "    *   The predicted protein structure will be downloaded once all cells have been executed. Note: This can take minutes to hours - see below.\n",
        "*   How long will this take?\n",
        "    *   Downloading the AlphaFold source code can take up to a few minutes.\n",
        "    *   Downloading and installing the third-party software can take up to a few minutes.\n",
        "    *   The search against genetic databases can take minutes to hours.\n",
        "    *   Running AlphaFold and generating the prediction can take minutes to hours, depending on the length of your protein and on which GPU-type Colab has assigned you.\n",
        "*   My Colab no longer seems to be doing anything, what should I do?\n",
        "    *   Some steps may take minutes to hours to complete.\n",
        "    *   If nothing happens or if you receive an error message, try restarting your Colab runtime via _Runtime_ > _Restart runtime_.\n",
        "    *   If this doesn’t help, try resetting your Colab runtime via _Runtime_ > _Factory reset runtime_.\n",
        "*   How does this compare to the open-source version of AlphaFold?\n",
        "    *   This Colab version of AlphaFold searches a selected portion of the BFD dataset and currently doesn’t use templates, so its accuracy is reduced in comparison to the full version of AlphaFold that is described in the [AlphaFold paper](https://doi.org/10.1038/s41586-021-03819-2) and [Github repo](https://github.com/deepmind/alphafold/) (the full version is available via the inference script).\n",
        "*   What is a Colab?\n",
        "    *   See the [Colab FAQ](https://research.google.com/colaboratory/faq.html).\n",
        "*   I received a warning “Notebook requires high RAM”, what do I do?\n",
        "    *   The resources allocated to your Colab vary. See the [Colab FAQ](https://research.google.com/colaboratory/faq.html) for more details.\n",
        "    *   You can execute the Colab nonetheless.\n",
        "*   I received an error “Colab CPU runtime not supported” or “No GPU/TPU found”, what do I do?\n",
        "    *   Colab CPU runtime is not supported. Try changing your runtime via _Runtime_ > _Change runtime type_ > _Hardware accelerator_ > _GPU_.\n",
        "    *   The type of GPU allocated to your Colab varies. See the [Colab FAQ](https://research.google.com/colaboratory/faq.html) for more details.\n",
        "    *   If you receive “Cannot connect to GPU backend”, you can try again later to see if Colab allocates you a GPU.\n",
        "    *   [Colab Pro](https://colab.research.google.com/signup) offers priority access to GPUs.\n",
        "*   I received an error “ModuleNotFoundError: No module named ...”, even though I ran the cell that imports it, what do I do?\n",
        "    *   Colab notebooks on the free tier time out after a certain amount of time. See the [Colab FAQ](https://research.google.com/colaboratory/faq.html#idle-timeouts). Try rerunning the whole notebook from the beginning.\n",
        "*   Does this tool install anything on my computer?\n",
        "    *   No, everything happens in the cloud on Google Colab.\n",
        "    *   At the end of the Colab execution a zip-archive with the obtained prediction will be automatically downloaded to your computer.\n",
        "*   How should I share feedback and bug reports?\n",
        "    *   Please share any feedback and bug reports as an [issue](https://github.com/deepmind/alphafold/issues) on Github.\n",
        "\n",
        "\n",
        "## Related work\n",
        "\n",
        "Take a look at these Colab notebooks provided by the community (please note that these notebooks may vary from our validated AlphaFold system and we cannot guarantee their accuracy):\n",
        "\n",
        "*   The [ColabFold AlphaFold2 notebook](https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/AlphaFold2.ipynb) by Sergey Ovchinnikov, Milot Mirdita and Martin Steinegger, which uses an API hosted at the Södinglab based on the MMseqs2 server ([Mirdita et al. 2019, Bioinformatics](https://academic.oup.com/bioinformatics/article/35/16/2856/5280135)) for the multiple sequence alignment creation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfPhvYgKC81B"
      },
      "source": [
        "# License and Disclaimer\n",
        "\n",
        "This is not an officially-supported Google product.\n",
        "\n",
        "This Colab notebook and other information provided is for theoretical modelling only, caution should be exercised in its use. It is provided ‘as-is’ without any warranty of any kind, whether expressed or implied. Information is not intended to be a substitute for professional medical advice, diagnosis, or treatment, and does not constitute medical or other professional advice.\n",
        "\n",
        "Copyright 2021 DeepMind Technologies Limited.\n",
        "\n",
        "\n",
        "## AlphaFold Code License\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0.\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "## Model Parameters License\n",
        "\n",
        "The AlphaFold parameters are made available for non-commercial use only, under the terms of the Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0) license. You can find details at: https://creativecommons.org/licenses/by-nc/4.0/legalcode\n",
        "\n",
        "\n",
        "## Third-party software\n",
        "\n",
        "Use of the third-party software, libraries or code referred to in the [Acknowledgements section](https://github.com/deepmind/alphafold/#acknowledgements) in the AlphaFold README may be governed by separate terms and conditions or license provisions. Your use of the third-party software, libraries or code is subject to any such terms and you should check that you can comply with any applicable restrictions or terms and conditions before use.\n",
        "\n",
        "\n",
        "## Mirrored Databases\n",
        "\n",
        "The following databases have been mirrored by DeepMind, and are available with reference to the following:\n",
        "* UniProt: v2021\\_03 (unmodified), by The UniProt Consortium, available under a [Creative Commons Attribution-NoDerivatives 4.0 International License](http://creativecommons.org/licenses/by-nd/4.0/).\n",
        "* UniRef90: v2021\\_03 (unmodified), by The UniProt Consortium, available under a [Creative Commons Attribution-NoDerivatives 4.0 International License](http://creativecommons.org/licenses/by-nd/4.0/).\n",
        "* MGnify: v2019\\_05 (unmodified), by Mitchell AL et al., available free of all copyright restrictions and made fully and freely available for both non-commercial and commercial use under [CC0 1.0 Universal (CC0 1.0) Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/).\n",
        "* BFD: (modified), by Steinegger M. and Söding J., modified by DeepMind, available under a [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by/4.0/). See the Methods section of the [AlphaFold proteome paper](https://www.nature.com/articles/s41586-021-03828-1) for details."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "AlphaFold.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
